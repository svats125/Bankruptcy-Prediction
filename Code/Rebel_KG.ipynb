{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3yVQjKUzJWG",
        "outputId": "e7df80f6-20e6-479d-8d59-50571ce22166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line -1, in parseImpl\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1732, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1523, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1734, in isEnabledFor\n",
            "    _acquireLock()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 226, in _acquireLock\n",
            "    _lock.acquire()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Drive**"
      ],
      "metadata": {
        "id": "l85EP1XdB00r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dxDkkL1eB_f",
        "outputId": "dcaf966c-64a5-4145-855d-f9fc027c7131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**REBEL MODEL**"
      ],
      "metadata": {
        "id": "1sGvcVurB6S4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "vV7Y0b9_zF2A",
        "outputId": "561a2032-be1f-42ad-e830-a8ae64827875"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7eb3ad3c4280>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3460da8db2f4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtriplets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0;31m from .generic import (\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mContextManagers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_torch_pytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_model_output_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_pytree.Context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1528\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1531\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0munused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_await\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_awaitable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_awaitable_nowait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_awaitable_wait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decomposition_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_register_decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_async.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_builtins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_register_builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/jit/_builtins.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_list_with_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_quadruple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_single\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_triple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/backends/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m from torch.backends import (\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mcpu\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mcuda\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "def extract_triplets(text):\n",
        "    triplets = []\n",
        "    relation, subject, relation, object_ = '', '', '', ''\n",
        "    text = text.strip()\n",
        "    current = 'x'\n",
        "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
        "        if token == \"<triplet>\":\n",
        "            current = 't'\n",
        "            if relation != '':\n",
        "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "                relation = ''\n",
        "            subject = ''\n",
        "        elif token == \"<subj>\":\n",
        "            current = 's'\n",
        "            if relation != '':\n",
        "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "            object_ = ''\n",
        "        elif token == \"<obj>\":\n",
        "            current = 'o'\n",
        "            relation = ''\n",
        "        else:\n",
        "            if current == 't':\n",
        "                subject += ' ' + token\n",
        "            elif current == 's':\n",
        "                object_ += ' ' + token\n",
        "            elif current == 'o':\n",
        "                relation += ' ' + token\n",
        "    if subject != '' and relation != '' and object_ != '':\n",
        "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
        "    return triplets\n",
        "\n",
        "# Load model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
        "gen_kwargs = {\n",
        "    \"max_length\": 256,\n",
        "    \"length_penalty\": 0,\n",
        "    \"num_beams\": 3,\n",
        "    \"num_return_sequences\": 3,\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3T3tvxyFFss"
      },
      "source": [
        "**KNOWLEDGE GRAPH GENERATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgAvL72xBKMT"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from IPython.display import display, Javascript\n",
        "\n",
        "#text = \"Total contract values are expected to be little changed on a sequential basis. Supply-side challenges remain, but the demand outlook remains strong\"\n",
        "news_folder='/content/drive/MyDrive/Major_Project/News/'\n",
        "triplets_dataset=[]\n",
        "cnt=0\n",
        "for comp in os.listdir(news_folder):\n",
        "    print(comp)\n",
        "    cnt=cnt+1\n",
        "    news_df =pd.read_csv(news_folder+comp)\n",
        "    triplets_list = []\n",
        "    for i in range(len(news_df)) :\n",
        "        #text = \"The government along with LIC is selling nearly 61 per cent stake in IDBI Bank and had in October 2022, invited bids from buyers\"\n",
        "        text=news_df['headline'][i]\n",
        "        # Tokenizer text\n",
        "        model_inputs = tokenizer(text, max_length=256, padding=True, truncation=True, return_tensors = 'pt')\n",
        "\n",
        "        # Generate\n",
        "        generated_tokens = model.generate(\n",
        "            model_inputs[\"input_ids\"].to(model.device),\n",
        "            attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
        "            **gen_kwargs,\n",
        "        )\n",
        "\n",
        "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
        "\n",
        "        # Extract text\n",
        "\n",
        "\n",
        "        # Extract triplets\n",
        "        for idx, sentence in enumerate(decoded_preds):\n",
        "        #    print(f'Prediction triplets sentence {idx}')\n",
        "            triplet=extract_triplets(sentence)\n",
        "        #   print(triplet)\n",
        "            triplets_list.extend(triplet)\n",
        "\n",
        "    trip_df=pd.DataFrame(triplets_list,columns=['head','type','tail'])\n",
        "    trip_df.to_csv(comp[:-4]+'_triplets.csv')\n",
        "    # files.download(comp[:-4]+'_triplets.csv')\n",
        "    # time.sleep(5)\n",
        "    # while any(fname.startswith(comp[:-4]) for fname in os.listdir('/content')):\n",
        "    #       time.sleep(5)\n",
        "    triplets_dataset.append(triplets_list)\n",
        "\n",
        "\n",
        "G = nx.Graph()\n",
        "for triplet in triplets_list:\n",
        "    subject, relation, obj = triplet\n",
        "    print(triplet)\n",
        "    G.add_node(triplet[subject])\n",
        "    G.add_node(triplet[obj])\n",
        "    G.add_edge(triplet[subject], triplet[obj], label=triplet[relation])\n",
        "\n",
        "    # Visualization\n",
        "pos = nx.spring_layout(G)\n",
        "nx.draw(G, pos, with_labels=True, font_weight='bold', node_size=2500, node_color='skyblue', font_size=8, edge_color='gray', width=3, alpha=0.7, font_color='black')\n",
        "labels = nx.get_edge_attributes(G, 'label')\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels,font_size=6)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EMBEDDINGS GENERATION**"
      ],
      "metadata": {
        "id": "PAeegoNIC1SV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "lkfik_drst9V",
        "outputId": "ba6460e1-addc-431a-a6ef-baa34a276f84"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pykeen'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-235f13238a55>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpykeen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriples\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTriplesFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpykeen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pykeen'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pykeen.triples import TriplesFactory\n",
        "from pykeen.pipeline import pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "\n",
        "# Assuming your dataframe has columns 'subject', 'predicate', 'object'\n",
        "triplet_folder='/content/drive/MyDrive/Major_Project/Triplets/'\n",
        "dist_ent_emb=[]\n",
        "dist_rel_emb=[]\n",
        "trans_ent_emb=[]\n",
        "trans_rel_emb=[]\n",
        "count=0\n",
        "for comp in os.listdir(triplet_folder):\n",
        "    print(count,comp)\n",
        "    count=count+1\n",
        "    triplet_df=pd.read_csv(triplet_folder+comp)\n",
        "    triples_factory = TriplesFactory.from_labeled_triples(triplet_df[['head', 'type', 'tail']].values,)\n",
        "\n",
        "    training = triples_factory\n",
        "    validation = triples_factory\n",
        "    testing = triples_factory\n",
        "\n",
        "    d=training\n",
        "    id_to_entity={v: k for k, v in d.entity_to_id.items()}\n",
        "    id_to_relation={v: k for k, v in d.relation_to_id.items()}\n",
        "\n",
        "    for i in d.map_triples(d.triples):\n",
        "        s,p,o =int(i[0]), int(i[1]), int(i[2])\n",
        "        h,r,t = id_to_entity[s], id_to_relation[p], id_to_entity[o]\n",
        "\n",
        "    result1 = pipeline(\n",
        "        model='DistMult',\n",
        "        loss=\"softplus\",\n",
        "        training=training,\n",
        "        testing=testing,\n",
        "        validation=validation,\n",
        "        model_kwargs=dict(embedding_dim=50, random_seed=42),  # Increase the embedding dimension\n",
        "        optimizer_kwargs=dict(lr=0.1),  # Adjust the learning rate\n",
        "        training_kwargs=dict(num_epochs=25, use_tqdm_batch=False),)  # Increase the number of epochs)\n",
        "\n",
        "    result2 = pipeline(\n",
        "        model='TransE',\n",
        "        loss=\"softplus\",\n",
        "        training=training,\n",
        "        testing=testing,\n",
        "        validation=validation,\n",
        "        model_kwargs=dict(embedding_dim=50, random_seed=42),  # Increase the embedding dimension\n",
        "        optimizer_kwargs=dict(lr=0.1),  # Adjust the learning rate\n",
        "        training_kwargs=dict(num_epochs=25, use_tqdm_batch=False),  # Increase the number of epochs\n",
        "    )\n",
        "\n",
        "    # The trained model is stored in the pipeline result\n",
        "    model1 = result1.model\n",
        "    model2 = result2.model\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    entity_embeddings1 = model1.entity_representations[0](indices=None).detach().cpu().numpy()\n",
        "    m = pca.fit(entity_embeddings1)\n",
        "    eu = m.transform(entity_embeddings1)\n",
        "    relation_embeddings1 = model1.relation_representations[0](indices=None).detach().cpu().numpy()\n",
        "    ru = pca.transform(relation_embeddings1)\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    entity_embeddings2 = model2.entity_representations[0](indices=None).detach().cpu().numpy()\n",
        "    m = pca.fit(entity_embeddings2)\n",
        "    eu = m.transform(entity_embeddings2)\n",
        "    relation_embeddings2 = model2.relation_representations[0](indices=None).detach().cpu().numpy()\n",
        "    ru = pca.transform(relation_embeddings2)\n",
        "\n",
        "    dist_ent_emb.append(entity_embeddings1)\n",
        "    trans_ent_emb.append(entity_embeddings2)\n",
        "    dist_rel_emb.append(relation_embeddings1)\n",
        "    trans_rel_emb.append(relation_embeddings2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Display the first few triples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8WqRK0ASNTc"
      },
      "outputs": [],
      "source": [
        "target=[1,1,1,0,1,1,0,0,0,1,1,0,0,0,0,0,0,1,1,1,0,0,0,0,1,1,1,0,1,1,0,0,0,1,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,0,1,1,1,0,0,0,0,1,1,1,0,0,0,0,1,0,1,1,1,0,1,0,1,1,1,1,0,1,0,0,0,1,1,1,0,1,1,0,0,1,1,0,1,0,0,1,1,1,1,0,0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIpyiRQfVFpZ",
        "outputId": "6a8ebb24-9511-4716-a583-b53fece5ae36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyDJJEXh5fMa"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dytD-BwFXEzY"
      },
      "outputs": [],
      "source": [
        "y_train=np.array(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms9t61IDCXsi"
      },
      "outputs": [],
      "source": [
        "dr=dist_rel_emb.copy()\n",
        "de=dist_ent_emb.copy()\n",
        "tr=trans_rel_emb.copy()\n",
        "te=trans_ent_emb.copy()\n",
        "# dist_rel_emb=dr.copy()\n",
        "# dist_ent_emb=de.copy()\n",
        "# trans_rel_emb=tr.copy()\n",
        "# trans_ent_emb=te.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZYRB4OfKIf8"
      },
      "outputs": [],
      "source": [
        "size=50\n",
        "ln=0\n",
        "for i in range(len(de)):\n",
        "  ln=len(de[i])\n",
        "  for j in range(ln,size):\n",
        "    de[i]=np.concatenate((de[i],[de[i][j%ln]]),axis=0)\n",
        "for i in range(len(dr)):\n",
        "  ln=len(dr[i])\n",
        "  for j in range(ln,size):\n",
        "    dr[i]=np.concatenate((dr[i],[dr[i][j%ln]]),axis=0)\n",
        "for i in range(len(tr)):\n",
        "  ln=len(tr[i])\n",
        "  for j in range(ln,size):\n",
        "    tr[i]=np.concatenate((tr[i],[tr[i][j%ln]]),axis=0)\n",
        "for i in range(len(te)):\n",
        "  ln=len(te[i])\n",
        "  for j in range(ln,size):\n",
        "    te[i]=np.concatenate((te[i],[te[i][j%ln]]),axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJrFtBHIOCn_"
      },
      "outputs": [],
      "source": [
        "for i in range(len(dist_rel_emb)):\n",
        "  dist_rel_emb[i] = dist_rel_emb[i][:7]\n",
        "for i in range(len(trans_ent_emb)):\n",
        "  trans_ent_emb[i] = trans_ent_emb[i][:7]\n",
        "for i in range(len(dist_ent_emb)):\n",
        "  dist_ent_emb[i] = dist_ent_emb[i][:7]\n",
        "for i in range(len(trans_rel_emb)):\n",
        "  trans_rel_emb[i] = trans_rel_emb[i][:7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugGXpsSfJSd1",
        "outputId": "298f8b26-6af6-4346-eb38-580858f31178"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(dist_rel_emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXhZDSIgNH6B",
        "outputId": "00e557fe-5881-4ef9-83dc-a4b03f79323b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 50)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTF1eI8NLFlC",
        "outputId": "e227c1af-c805-4c28-e64e-efb328406f2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 50)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dist_rel_emb[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS9tQuBKMbST"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "dist_merged  = []\n",
        "trans_merged = []\n",
        "for i in range(len(dist_ent_emb)):\n",
        "  dist_merged.append(np.concatenate((dr[i], de[i])))\n",
        "  trans_merged.append(np.concatenate((tr[i], te[i])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mUuC6-GJXzS",
        "outputId": "e0e1238f-01c1-43d8-bbe4-ef0d95f2291c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100, 50)\n",
            "(100, 50)\n"
          ]
        }
      ],
      "source": [
        "print(dist_merged[i].shape)\n",
        "print(trans_merged[i].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i77fSLkPKW1W",
        "outputId": "f917f1e9-c370-4f84-ec00-340b35fb8aac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14, 50)\n",
            "(14, 50)\n"
          ]
        }
      ],
      "source": [
        "print(trans_merged[0].shape)\n",
        "print(dist_merged[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dZAzPf8W8nK"
      },
      "outputs": [],
      "source": [
        "X1_train = np.array(dist_merged)\n",
        "X2_train = np.array(trans_merged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb9yJ7kjXVqN",
        "outputId": "915d3fec-3de8-4c16-b473-7b463c36ea47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(102, 14, 50)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X1_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSoUKOuCY7t3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1_train, y_train, test_size=0.2, random_state=42)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9ZWa-uuZU8o",
        "outputId": "fd9b5115-4b58-4ffc-88cf-48c3780fffc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(81, 14, 50)\n",
            "(81, 14, 50)\n"
          ]
        }
      ],
      "source": [
        "print(X1_train.shape)\n",
        "print(X2_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM MODEL**"
      ],
      "metadata": {
        "id": "OwzcP2x5DHA9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM5qL_FBFOFO",
        "outputId": "7d5abb80-5216-45b5-e060-961544f4ebc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 64)                29440     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,201\n",
            "Trainable params: 33,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "# Define your model\n",
        "model = Sequential()\n",
        "\n",
        "# Add LSTM layer\n",
        "model.add(LSTM(units=64, input_shape=(100,50)))\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "# Add Dense layer for binary classification\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6anxLwoBiE96",
        "outputId": "e9a0860e-46f6-4004-d4d0-5dc44732dc39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 64)                29440     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,201\n",
            "Trainable params: 33,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "# Add LSTM layer\n",
        "model1.add(LSTM(units=64, input_shape=(100,50)))\n",
        "model1.add(Dense(units=16, activation='relu'))\n",
        "model1.add(Dense(units=32, activation='relu'))\n",
        "model1.add(Dense(units=64, activation='relu'))\n",
        "# Add Dense layer for binary classification\n",
        "model1.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "print(model1.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpw3CIF_FT1a",
        "outputId": "82509ebb-d28d-4264-fe02-643133a61f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3/3 [==============================] - 4s 58ms/step - loss: 0.6924 - accuracy: 0.5432\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.6890 - accuracy: 0.5432\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.6860 - accuracy: 0.5432\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.6832 - accuracy: 0.5432\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6795 - accuracy: 0.5432\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.6759 - accuracy: 0.5432\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6706 - accuracy: 0.5432\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.6652 - accuracy: 0.5432\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6570 - accuracy: 0.5432\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6480 - accuracy: 0.5432\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.6357 - accuracy: 0.5432\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.6182 - accuracy: 0.5556\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.5990 - accuracy: 0.6049\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.5622 - accuracy: 0.6420\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.5185 - accuracy: 0.7531\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4747 - accuracy: 0.8765\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.4510 - accuracy: 0.9506\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.4272 - accuracy: 0.9506\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4185 - accuracy: 0.8889\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.3724 - accuracy: 0.9630\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.3712 - accuracy: 0.9753\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.3485 - accuracy: 0.9506\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.3034 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.2779 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.2430 - accuracy: 0.9877\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.2085 - accuracy: 0.9877\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1767 - accuracy: 0.9877\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1503 - accuracy: 0.9877\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1257 - accuracy: 0.9877\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1043 - accuracy: 0.9877\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X1_train, y1_train, batch_size=32, epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5sheHLgX5hP",
        "outputId": "77e36427-badf-4db6-8c85-cad74eddf064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3/3 [==============================] - 4s 95ms/step - loss: 0.6950 - accuracy: 0.4444\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.6899 - accuracy: 0.6667\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.6866 - accuracy: 0.7160\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.6821 - accuracy: 0.7778\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6766 - accuracy: 0.7901\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.6688 - accuracy: 0.8148\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.6581 - accuracy: 0.8395\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.6436 - accuracy: 0.8395\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.6215 - accuracy: 0.8519\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.5864 - accuracy: 0.8519\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5367 - accuracy: 0.8272\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.4900 - accuracy: 0.9259\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.4459 - accuracy: 0.9136\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5240 - accuracy: 0.8765\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.3887 - accuracy: 0.9259\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.4158 - accuracy: 0.9136\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.4239 - accuracy: 0.9012\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.3961 - accuracy: 0.9136\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.3532 - accuracy: 0.9259\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.3139 - accuracy: 0.9506\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.2766 - accuracy: 0.9630\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.2449 - accuracy: 0.9506\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.2076 - accuracy: 0.9506\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1792 - accuracy: 0.9630\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.1514 - accuracy: 0.9630\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1397 - accuracy: 0.9630\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1220 - accuracy: 0.9753\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1093 - accuracy: 0.9753\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0997 - accuracy: 0.9753\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0900 - accuracy: 0.9753\n"
          ]
        }
      ],
      "source": [
        "history1 = model1.fit(X2_train, y2_train, batch_size=32, epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PERFORMANCE METRICS OF DISTMULT EMBEDDINGS + LSTM**"
      ],
      "metadata": {
        "id": "XMhhOZLIDiFK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ-qERklX_HP",
        "outputId": "01a122de-48b2-44fb-9cf0-c49f793bf66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 500ms/step\n",
            "Accuracy : 57.14285714285714\n",
            "Sensitivity :  30.76923076923077 %\n",
            "Specificity :  100.0 %\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      1.00      0.64         8\n",
            "           1       1.00      0.31      0.47        13\n",
            "\n",
            "    accuracy                           0.57        21\n",
            "   macro avg       0.74      0.65      0.56        21\n",
            "weighted avg       0.80      0.57      0.54        21\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Assuming X1_test and y1_test are your test data and labels respectively\n",
        "# Predict on the test data\n",
        "y_pred_prob = model.predict(X1_test)\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model using sklearn.metrics.accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = metrics.accuracy_score(y1_test, y_pred)*100\n",
        "print(\"Accuracy :\",accuracy)\n",
        "print(\"Sensitivity : \", metrics.recall_score(y1_test , y_pred)*100,\"%\")\n",
        "print(\"Specificity : \", metrics.recall_score(np.logical_not(y1_test) ,np.logical_not(y_pred))*100,\"%\")\n",
        "print(\"Classification Report : \")\n",
        "print(metrics.classification_report(y1_test, y_pred))\n",
        "\n",
        "# Print the accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PERFORMANCE METRICS OF TRANS-E EMBEDDINGS + LSTM**"
      ],
      "metadata": {
        "id": "p2wB1JSzDwwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTcBIUkEa_dA",
        "outputId": "7c8224e1-a33f-4ae7-9a7b-6ac471189ec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 489ms/step\n",
            "Accuracy : 57.14285714285714\n",
            "Sensitivity :  30.76923076923077 %\n",
            "Specificity :  100.0 %\n",
            "Classification Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      1.00      0.64         8\n",
            "           1       1.00      0.31      0.47        13\n",
            "\n",
            "    accuracy                           0.57        21\n",
            "   macro avg       0.74      0.65      0.56        21\n",
            "weighted avg       0.80      0.57      0.54        21\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_prob1 = model1.predict(X2_test)\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1)\n",
        "y_pred1 = (y_pred_prob1 > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model using sklearn.metrics.accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = metrics.accuracy_score(y2_test, y_pred)*100\n",
        "print(\"Accuracy :\",accuracy)\n",
        "print(\"Sensitivity : \", metrics.recall_score(y2_test , y_pred)*100,\"%\")\n",
        "print(\"Specificity : \", metrics.recall_score(np.logical_not(y2_test) ,np.logical_not(y_pred))*100,\"%\")\n",
        "print(\"Classification Report : \")\n",
        "print(metrics.classification_report(y2_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}